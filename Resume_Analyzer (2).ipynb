{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8WA5f0fne-q",
    "outputId": "ebb4afc9-4c16-41a4-d129-dc4208db40e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.1.17)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.6.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.1.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-openai) (0.1.52)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-openai) (1.26.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.54)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.10.11)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.1.17)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.6.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (0.1.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\hooda\\anaconda3\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (1.10.11)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hooda\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: typing-inspect==0.8.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect==0.8.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect==0.8.0) (4.11.0)\n",
      "Collecting typing_extensions==4.5.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "Successfully installed typing_extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.111.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "openai 1.26.0 requires typing-extensions<5,>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "sqlalchemy 2.0.25 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "unstructured-client 0.22.0 requires typing-extensions>=4.7.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "unstructured-client 0.22.0 requires typing-inspect>=0.9.0, but you have typing-inspect 0.8.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic==1.10.11 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (1.10.11)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from pydantic==1.10.11) (4.5.0)\n",
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3973 sha256=033050a26c1662937ffff4a55337212398c0dc2ba2fa7e623100e32faa390f0a\n",
      "  Stored in directory: c:\\users\\hooda\\appdata\\local\\pip\\cache\\wheels\\0f\\0e\\7a\\3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unstructured-client 0.22.0 requires typing-inspect>=0.9.0, but you have typing-inspect 0.8.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken\n",
    "!pip install typing-inspect==0.8.0\n",
    "!pip install typing_extensions==4.5.0\n",
    "!pip install pydantic==1.10.11\n",
    "!pip install docx2txt\n",
    "!pip install --upgrade --quiet  langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\hooda\\anaconda3\\lib\\site-packages (4.11.0)\n",
      "Requirement already satisfied: typing-inspect in c:\\users\\hooda\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hooda\\anaconda3\\lib\\site-packages (from typing-inspect) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing-extensions\n",
    "!pip install typing-inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vUFSOmrNniL8"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "14s4Pw3dToNS"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from typing import Iterator\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "sktMK0r6T4DR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Mb0YMF6UT9Kk"
   },
   "outputs": [],
   "source": [
    "pdfreader = PdfReader('Anubhavs M Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bkWX0ms_UT-o"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fWwLuUBvUWwI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ANUBHAV HOODA LinkedIn | +91- 9911865100 | g.dev | hoodaanubhav@gmail.com | GitHub Skills  • C++ | Python | Java | JavaScript | TypeScript | C | MongoDB | MSSQL | Node | Express | React | Vue | NoSQL | Git • Deep Learning | Natural Language Processing(NLP) | Scikit-learn | TensorFlow | PyTorch | Feature Engineering • Data Transformation | AWS EC2| Cloud Computing | Unit Testing | Lambda | OOP | Unity 2D | Performance Evaluation Experience  Artiﬁcial Intelligence and  Machine Learning Head Google Developer Students Club 07/2023 - Current • As a mentor, I support and guide my college juniors in machine learning,', 'Artiﬁcial Intelligence and  Machine Learning Head Google Developer Students Club 07/2023 - Current • As a mentor, I support and guide my college juniors in machine learning, assisting them with their initial machine learning projects. • Facilitated exposure by organizing multiple TED Talks and inviting industry experts as guest speakers on behalf of the Google Developer Student Club (GDSC) group. • Collaborated with peers to create engaging and informative events, fostering a vibrant learning community. Machine Learning Mentor Virtual Cyber Labs New Delhi, India 05/2021 - 06/2023 • As a mentor, I Facilitated workshops and hands-on sessions, enabling students to apply theoretical concepts to practical scenarios. • Mentored students through machine learning projects, helping them understand', 'I Facilitated workshops and hands-on sessions, enabling students to apply theoretical concepts to practical scenarios. • Mentored students through machine learning projects, helping them understand algorithms, best practices, and real-world applications. • Emphasized communication, collaboration, and problem-solving skills alongside technical expertise. • Witnessing mentees evolve into conﬁdent machine learning practitioners brings immense satisfaction. Contributing to their success fuels my commitment to mentorship. Team Leader Viral Fission New Delhi, India 10/2019 - 03/2021 • My role involved more than just managing workﬂows; it was about fostering collaboration, problem-solving, and effective communication. I learned the art of de-escalating high-pressure situations, ensuring our team', 'more than just managing workﬂows; it was about fostering collaboration, problem-solving, and effective communication. I learned the art of de-escalating high-pressure situations, ensuring our team achieved an impressive 83% success rate. • I orchestrated a dynamic group of 32 professionals within our escalation taskforce. • By implementing a customer-centric policy, we boosted retention rates by 42% over two years • Beyond the metrics, there’s the intangible joy of watching a meticulously crafted team come together  Key Achievements  SIH-2023 Winner 🔗 • Developed a CNN model for Identiﬁcation and Extraction of Forward Error Correction (FEC) schemes of unknown demodulated signals • Used Matlab to generate more', 'SIH-2023 Winner 🔗 • Developed a CNN model for Identiﬁcation and Extraction of Forward Error Correction (FEC) schemes of unknown demodulated signals • Used Matlab to generate more than 3 gigs of BPSK , QPSK , 8-PSK modulation schemes and 6 fec algorithms including Hamming, BCH, TPC, Turbo, Convolutional, LDPC. (SIH-1447) • This model showed an average of 92 percent accuracy in all of the above mentioned subclasses. Flipkart GRiD 5.0 🔗 • Made Armstrong, leveraged Reinforcement learning and opencv to fully control the robotic arm capable of detecting and interacting with its surrounding objects. • Iterative design process done on SolidWorks, 3D printing and code adjustments for optimal performance. Certiﬁcations', 'robotic arm capable of detecting and interacting with its surrounding objects. • Iterative design process done on SolidWorks, 3D printing and code adjustments for optimal performance. Certiﬁcations  • Advanced Machine Learning Algorithms - By Andrew Ng (Build neural networks with TensorFlow | Decision Trees - Random forests and boosted trees | Multi-class classiﬁcation ) • Supervised Machine Learning: Regression and Classiﬁcation - By Andrew Ng (NumPy | Scikit-learn | linear & logistic regression | classiﬁcation | supervised ml ) Education  Bachelor of Technology Galgotias College Noida, Delhi 08/2021 - 06/2025 •', '| supervised ml ) Education  Bachelor of Technology Galgotias College Noida, Delhi 08/2021 - 06/2025 • Major in Computer Engineering and Artiﬁcial Intelligence Machine Learning High School Vishal Bharti Public School Paschim Vihar, Delhi 08/2008 - 06/2021 • Major in Physics, Chemistry and Mathematics along with computer programming (85 percent)  Projects  • M E E T A I R T : Large language model to tackle complex prompts. Link to Linkedin Post (07/2023) • T A M E T - R E X : Chrome T-Rex controlled by Reinforcement Learning using a reward based approach. Link to LinkedIn Post (09/2023) Others', 'to tackle complex prompts. Link to Linkedin Post (07/2023) • T A M E T - R E X : Chrome T-Rex controlled by Reinforcement Learning using a reward based approach. Link to LinkedIn Post (09/2023) Others  • Gold Award : Won 1st prize for the development of the best Drone Control System in HackGCET in Delhi (09/2021)']\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "cleaned_texts = [chunk.replace(\"\\n\", \" \") for chunk in texts]\n",
    "cleaned_texts = [chunk.replace(\"_\", \"\") for chunk in cleaned_texts ]\n",
    "# cleaned_texts = re.sub('_{2,}', ' ', cleaned_texts)\n",
    "print(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fCEJWAssnWce"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "UwEORuFUYOfU"
   },
   "outputs": [],
   "source": [
    "document_search = FAISS.from_texts(cleaned_texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "et49VjpVZAXc"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "FjKjmfFNZB4s"
   },
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "WQvXZDjDaLY6",
    "outputId": "04dd1d43-e1b8-40be-bb9a-09be7fca89b0"
   },
   "outputs": [],
   "source": [
    "query = \"What are the skills?\"\n",
    "docs = document_search.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "I0ZmaICaaLoS",
    "outputId": "7bebc922-7e8c-48fa-da56-5163de6d57d1"
   },
   "outputs": [],
   "source": [
    "query = \"What are the projects?\"\n",
    "docs = document_search.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "29m1IkXTaLsA",
    "outputId": "407edc4c-d1fd-45c5-d518-ea440fedbac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the candidate\\'s resume, it is evident that they have a strong background in machine learning, with a Bachelor\\'s degree in Computer Engineering and Artificial Intelligence and experience as an Artificial Intelligence and Machine Learning Head at Google Developer Students Club. Their technical skills include proficiency in languages such as C++, Python, and Java, as well as experience with deep learning, natural language processing, and cloud computing.\\n\\nIn terms of experience, the candidate has worked on various projects, including the development of a CNN model for identification and extraction of Forward Error Correction (FEC) schemes and a large language model to tackle complex prompts. They have also facilitated workshops and mentored students through machine learning projects, emphasizing communication, collaboration, and problem-solving skills.\\n\\nFrom a cultural fit perspective, the candidate\\'s experience as a team leader at Viral Fission and their statement of \"contributing to their success fuels my commitment to mentorship\" demonstrate a strong desire for teamwork and a positive attitude towards mentoring and developing others.\\n\\nOverall, the candidate\\'s technical skills and experience align well with the responsibilities and expectations outlined in the job description for a Back End Software Engineer. However, it is worth noting that their experience seems to be more focused on machine learning rather than back-end development. This may be an area for'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"You are a seasoned recruiter tasked with evaluating the suitability of a candidate for the position of Back End Software Engineer based on their resume. Your assessment should be thorough and insightful, reflecting both the candidate's qualifications and the specific requirements outlined in the job description. Consider the candidate's technical skills, experience, and potential cultural fit within the organization. Provide a detailed analysis, including a numerical rating from 1 to 10 along with a comprehensive explanation justifying the score. Take into account both the strengths and areas for improvement highlighted in the resume and how well they align with the responsibilities and expectations outlined in the job description. Aim for a holistic assessment that goes beyond surface-level evaluation.\"\n",
    "docs = document_search.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = docx2txt.TextExtractor()\n",
    "with open(\"job_fit.docx\", \"rb\") as f:\n",
    "    job_description = text_extractor.extract(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_description = \"\"\"\n",
    "#     The Back End Software Engineer is responsible for the following:\n",
    "#     • Develop server-side logic, definition and maintenance of the central database, and ensure high performance and responsiveness to requests from the front-end developers.\n",
    "#     • Integrate user-facing elements developed by front-end developers with server-side applications.\n",
    "#     • Collaborate with front-end developers, customers, users and Product Managers to establish objectives and design functional, cohesive codes to enhance the user experience.\n",
    "#     • Keep abreast of novel technical concepts and markets.\n",
    "#     • Provide technical leadership and documentation to developers and stakeholders.\n",
    "#     • Apply usability procedures and principles as defined at the project or Product Line level or through customer input.\n",
    "#     • Build prototypes, products and systems that meet the project quality standards and requirements.\n",
    "#     • Contribute to and support re-use through common components that are well documented and tested\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBased on the job description and the resume provided, the resume appears to match the job description quite well. The resume highlights experience and skills in relevant areas such as machine learning, artificial intelligence, and programming languages like Python, Java, and JavaScript. Additionally, the resume showcases experience in mentoring and collaborating with others, which are important skills for a back end software engineer. Overall, I would estimate that the resume matches the job description at around 85-90%.\\n\\nOne critique of the resume is that it could benefit from including more specific examples of projects or accomplishments, particularly in the experience section. This would help provide more concrete evidence of the candidate\\'s skills and experiences. Additionally, the resume could benefit from being more concise and organized. Some sections, such as \"Key Achievements\" and \"Projects,\" could be combined or further broken down into sub-sections to make the resume easier to read and navigate.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"Resume:\\n{cleaned_texts}\\n\\nJob Description:\\n{job_description}\\n\\n Analyze how well the resume matches the job description, \\\n",
    "        then Analyze the resume and provide an estimate percentage of how well it matches the job description\\\n",
    "        Additionally, provide critiques on the resume:\"\n",
    "docs = document_search.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume_job_match(cleaned_texts, job_description):    \n",
    "    query =  f\"Resume:\\n{cleaned_texts}\\n\\nJob Description:\\n{job_description}\\n\\n Analyze how well the resume matches the job description, \\\n",
    "        then Analyze the resume and provide an estimate percentage of how well it matches the job description\\\n",
    "        Additionally, provide critiques on the resume:\"\n",
    "    docs = document_search.similarity_search(query)\n",
    "    chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_resume_job_match(cleaned_texts,job_description)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
